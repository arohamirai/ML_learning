{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 、文件位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_path = \"./image/train\"\n",
    "testset_path = \"./image/test\"\n",
    "output_path = \"./output\"\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "image_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、创建 TFRecords文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import groupby\n",
    "from scipy import misc\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class 信息\n",
    "breeds_with_path = glob.glob(trainset_path + \"/*\")\n",
    "breeds = list(map(lambda x:x.split(\"/\")[3],breeds_with_path))\n",
    "breeds_dict = dict(zip(breeds, [x for x in range(len(breeds))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(breeds_dict[\"cat\"])\n",
    "print(breeds_dict[\"bird\"])\n",
    "print(breeds_dict[\"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_record(dataset_path,output_location):\n",
    "    # 获取数据集下所有文件路径\n",
    "    dataset_files = glob.glob(dataset_path + \"/*/*.jpg\")\n",
    "    # 分离出claess信息,得到（class,file_path）对的列表\n",
    "    image_filepath_with_breed = list(map(lambda file_path:(file_path.split(\"/\")[3],file_path),dataset_files))\n",
    "    \n",
    "    #每个TFRecord文件保存10个图片\n",
    "    nums_per_file = 10\n",
    "    writer = None\n",
    "    \n",
    "    # 记录当前读到的图像index\n",
    "    current_index = 0\n",
    "    for breed, file_path in image_filepath_with_breed:\n",
    "        if current_index % nums_per_file == 0:\n",
    "            if writer:\n",
    "                print(\"current_index = \",current_index,\"\\n\")\n",
    "                writer.close()\n",
    "            \n",
    "            # 格式化字符串\n",
    "            record_filename = \"{output_location}{current_index}.tfrecords\".format(\n",
    "            output_location = output_location,\n",
    "            current_index = current_index)\n",
    "            \n",
    "            writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "            \n",
    "        current_index += 1\n",
    "        \n",
    "        # 读取图像并转换为tf.example格式\n",
    "        image = misc.imread(file_path)\n",
    "            \n",
    "        # 图像转换为Byte型\n",
    "        image_raw = image.tobytes()\n",
    "        \n",
    "        example = tf.train.Example(features = \n",
    "                                  tf.train.Features(feature = {\n",
    "                    \"label\": tf.train.Feature(int64_list = tf.train.Int64List(value = [breeds_dict[breed]])),\n",
    "                    \"image_raw\": tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_raw]))   \n",
    "                }     \n",
    "            )    \n",
    "        )\n",
    "        \n",
    "        # 写入文件\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    # 关闭最后一个文件\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create_record(trainset_path,output_path + \"/training-images/\")\n",
    "#create_record(testset_path,output_path + \"/testing-images/\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 读取TFRecord 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames =tf.train.match_filenames_once(output_path + \"/training-images/*.tfrecords\")\n",
    "#[\"/home/lile/ML_learning/ML_framework/output/training-images/10.tfrecords\",\"/home/lile/ML_learning/ML_framework/output/training-images/0.tfrecords\"] #\n",
    "filenames_queue = tf.train.string_input_producer(filenames, shuffle = True)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filenames_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features = {\n",
    "        \"label\":tf.FixedLenFeature([],tf.int64),\n",
    "        \"image_raw\":tf.FixedLenFeature([],tf.string)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解码图像数据\n",
    "im = tf.decode_raw(features[\"image_raw\"],tf.uint8)\n",
    "#im1 = \n",
    "image = tf.reshape(im,(image_height,image_width,image_channels))\n",
    "label = tf.cast(features[\"label\"],tf.int32)\n",
    "\n",
    "# 组合训练数据\n",
    "batch_size = 3\n",
    "capacity = 1000 + 3*batch_size\n",
    "min_after_dequeue = 10*batch_size\n",
    "image_batch, label_batch = tf.train.shuffle_batch_join(\n",
    "[(image,label)],batch_size = batch_size,\n",
    "capacity = capacity,min_after_dequeue = min_after_dequeue\n",
    ")\n",
    "init = [tf.global_variables_initializer(),tf.local_variables_initializer()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义w,b初始化函数\n",
    "def weights_initializer(shape, stddev = 0.1):\n",
    "    weights = tf.Variable(tf.truncated_normal_initializer(shape,stddev))\n",
    "    return weights\n",
    "\n",
    "def bias_initializer(shape,constant = 0.0):\n",
    "    bias = tf.Variable(tf.constant(constant,shape,dtype = tf.float32))\n",
    "    return bias\n",
    "    \n",
    "    \n",
    "# 输入层\n",
    "with tf.name_scope(\"input\") as scope:\n",
    "    x = tf.placeholder(tf.float32,shape = [None, image_width,image_height,image_channels])\n",
    "    y = tf.placeholder(tf.int32,shape = [None, image_width,image_height,image_channels])\n",
    "\n",
    "#卷积层一\n",
    "with tf.name_scope(\"conv1\") as scope:\n",
    "    # 按《TensorFlow 实战》 中为编写，下同\n",
    "    # 实际 96核\n",
    "    w = weights_initializer(shape = [11, 11, 3, 64], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [64],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(x, w, strides = [1,4,4,1] padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu = tf.nn.relu(bias, name = scope)\n",
    "    # 局部响应归一化\n",
    "    lrn = tf.nn.lrn(relu, 4,bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='lrn1' )\n",
    "    # 池化\n",
    "    pool1 = tf.nn.max_pool(lrn, ksize = [1,3,3,1], strides = [1,2,2,1], padding = \"VALID\")\n",
    "    \n",
    "#卷积层二\n",
    "with tf.name_scope(\"conv2\") as scope:\n",
    "    # 实际 256核\n",
    "    w = weights_initializer(shape = [5, 5, 64, 192], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [192],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(pool1, w, strides = [1,1,1,1] padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu = tf.nn.relu(bias, name = scope)\n",
    "    # 局部响应归一化\n",
    "    lrn = tf.nn.lrn(relu, 4,bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='lrn2' )\n",
    "    # 池化\n",
    "    pool2 = tf.nn.max_pool(lrn, ksize = [1,3,3,1], strides = [1,2,2,1], padding = \"VALID\")\n",
    "\n",
    "#卷积层三\n",
    "with tf.name_scope(\"conv3\") as scope:\n",
    "    # 实际 384 核,相同 \n",
    "    w = weights_initializer(shape = [3, 3, 192, 384], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [384],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(pool2, w, strides = [1,1,1,1] padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu3 = tf.nn.relu(bias, name = scope)\n",
    "\n",
    "#卷积层四\n",
    "with tf.name_scope(\"conv3\") as scope:\n",
    "    # 实际 384 核, 相同\n",
    "    w = weights_initializer(shape = [3, 3, 384, 256], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [256],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(relu3, w, strides = [1,1,1,1] padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu4 = tf.nn.relu(bias, name = scope)\n",
    "\n",
    "#卷积层五\n",
    "with tf.name_scope(\"conv1\") as scope:\n",
    "    # 实际 256核\n",
    "    w = weights_initializer(shape = [3, 3, 256, 256], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [256],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(relu4, w, strides = [1,4,4,1] padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu = tf.nn.relu(bias, name = scope)\n",
    "    # 池化\n",
    "    pool5 = tf.nn.max_pool(relu, ksize = [1,3,3,1], strides = [1,2,2,1], padding = \"VALID\")\n",
    "    \n",
    "\n",
    "    \n",
    "# 定义训练代价函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #在迭代控制中,记得添加tf.initialize_local_variables(),官网教程没有说明,但是如\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess = sess, coord = coord)\n",
    "    \n",
    "    #y1,y2 = sess.run([image_batch, label_batch])\n",
    "    \n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y1.shape)\n",
    "plt.figure(0)\n",
    "plt.imshow(y1[0])\n",
    "plt.figure(1)\n",
    "plt.imshow(y1[1])\n",
    "plt.figure(2)\n",
    "plt.imshow(y1[2])\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

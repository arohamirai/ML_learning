{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 、文件位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_path = \"./image/train\"\n",
    "testset_path = \"./image/test\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "image_channels = 3\n",
    "\n",
    "#总共3类\n",
    "num_breed = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、创建 TFRecords文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import groupby\n",
    "from scipy import misc\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class 信息\n",
    "breeds_with_path = glob.glob(trainset_path + \"/*\")\n",
    "breeds = list(map(lambda x:x.split(\"/\")[3],breeds_with_path))\n",
    "breeds_dict = dict(zip(breeds, [x for x in range(len(breeds))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_record(dataset_path,output_location):\n",
    "    # 获取数据集下所有文件路径\n",
    "    dataset_files = glob.glob(dataset_path + \"/*/*.jpg\")\n",
    "    # 分离出claess信息,得到（class,file_path）对的列表\n",
    "    image_filepath_with_breed = list(map(lambda file_path:(file_path.split(\"/\")[3],file_path),dataset_files))\n",
    "    \n",
    "    #每个TFRecord文件保存10个图片\n",
    "    nums_per_file = 10\n",
    "    writer = None\n",
    "    \n",
    "    # 记录当前读到的图像index\n",
    "    current_index = 0\n",
    "    for breed, file_path in image_filepath_with_breed:\n",
    "        if current_index % nums_per_file == 0:\n",
    "            if writer:\n",
    "                print(\"current_index = \",current_index,\"\\n\")\n",
    "                writer.close()\n",
    "            \n",
    "            # 格式化字符串\n",
    "            record_filename = \"{output_location}{current_index}.tfrecords\".format(\n",
    "            output_location = output_location,\n",
    "            current_index = current_index)\n",
    "            \n",
    "            writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "            \n",
    "        current_index += 1\n",
    "        \n",
    "        # 读取图像并转换为tf.example格式\n",
    "        image = misc.imread(file_path)\n",
    "            \n",
    "        # 图像转换为Byte型\n",
    "        image_raw = image.tobytes()\n",
    "        \n",
    "        example = tf.train.Example(features = \n",
    "                                  tf.train.Features(feature = {\n",
    "                    \"label\": tf.train.Feature(int64_list = tf.train.Int64List(value = [breeds_dict[breed]])),\n",
    "                    \"image_raw\": tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_raw]))   \n",
    "                }     \n",
    "            )    \n",
    "        )\n",
    "        \n",
    "        # 写入文件\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    # 关闭最后一个文件\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create_record(trainset_path,output_path + \"/training-images/\")\n",
    "#create_record(testset_path,output_path + \"/testing-images/\")\n",
    "print(\"finished\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 读取TFRecord 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "filenames =tf.train.match_filenames_once(output_path + \"/training-images/*.tfrecords\")\n",
    "#[\"/home/lile/ML_learning/ML_framework/output/training-images/10.tfrecords\",\"/home/lile/ML_learning/ML_framework/output/training-images/0.tfrecords\"] #\n",
    "filenames_queue = tf.train.string_input_producer(filenames, shuffle = True)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filenames_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features = {\n",
    "        \"label\":tf.FixedLenFeature([],tf.int64),\n",
    "        \"image_raw\":tf.FixedLenFeature([],tf.string)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解码图像数据\n",
    "im = tf.decode_raw(features[\"image_raw\"],tf.uint8) \n",
    "image = tf.reshape(im,(image_height,image_width,image_channels))\n",
    "lab = tf.cast(features[\"label\"],tf.int32)\n",
    "label = tf.one_hot(indices = lab, depth = num_breed,\n",
    "                   on_value = 1.0, off_value = 0.0,\n",
    "                   axis = -1)\n",
    "\n",
    "# 组合训练数据\n",
    "batch_size = 3\n",
    "capacity = 1000 + 3*batch_size\n",
    "min_after_dequeue = 10*batch_size\n",
    "image_batch, label_batch = tf.train.shuffle_batch_join(\n",
    "[(image,label)],batch_size = batch_size,\n",
    "capacity = capacity,min_after_dequeue = min_after_dequeue\n",
    ")\n",
    "init = [tf.global_variables_initializer(),tf.local_variables_initializer()]\n",
    "\n",
    "print(type(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### 各层图片尺寸 \n",
    "# input   [batch_size, 224, 224, 3]\n",
    "# conv1   [32, 56, 56, 64]\n",
    "# pool1   [32, 27, 27, 64]\n",
    "# conv2   [32, 27, 27, 192]\n",
    "# pool2   [32, 13, 13, 192]\n",
    "# conv3   [32, 13, 13, 384]\n",
    "# conv4   [32, 13, 13, 256]\n",
    "# conv5   [32, 13, 13, 256]\n",
    "# pool5   [32, 6, 6, 256]\n",
    "\n",
    "\n",
    "# 定义w,b初始化函数\n",
    "def weights_initializer(shape, stddev = 0.1):\n",
    "    weights = tf.Variable(tf.truncated_normal(shape,stddev = stddev))\n",
    "    return weights\n",
    "\n",
    "def bias_initializer(shape,constant = 0.0):\n",
    "    bias = tf.Variable(tf.constant(constant, shape =shape, dtype = tf.float32))\n",
    "    return bias\n",
    "\n",
    "def fc_weights_initializer(num_in, num_out, stddev = 0.1, constant = 0.0):\n",
    "    weight = tf.Variable(tf.truncated_normal(shape = [num_in, num_out],stddev = stddev))\n",
    "    bias = tf.Variable(tf.constant(constant, shape =[1, num_out], dtype = tf.float32))\n",
    "    return weight, bias\n",
    "\n",
    "#def interface(x):\n",
    "    # 输入层\n",
    "with tf.name_scope(\"input\") as scope:\n",
    "    x = tf.placeholder(tf.float32,shape = [None, image_height, image_width, image_channels])\n",
    "    y = tf.placeholder(tf.float32,shape = [None,num_breed])\n",
    "\n",
    "    #卷积层一\n",
    "with tf.name_scope(\"conv1\") as scope:\n",
    "    # 按《TensorFlow 实战》 中为编写，下同\n",
    "    # 实际 96核\n",
    "    w = weights_initializer(shape = [11, 11, 3, 96], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [96],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(x, w, strides = [1,4,4,1], padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu = tf.nn.relu(bias, name = scope)\n",
    "    # 局部响应归一化\n",
    "    lrn = tf.nn.lrn(relu, 4,bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='lrn1' )\n",
    "    # 池化\n",
    "    pool1 = tf.nn.max_pool(lrn, ksize = [1,3,3,1], strides = [1,2,2,1], padding = \"VALID\")\n",
    "    \n",
    "    #卷积层二\n",
    "with tf.name_scope(\"conv2\") as scope:\n",
    "    # 实际 256核\n",
    "    w = weights_initializer(shape = [5, 5, 96, 256], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [256],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(pool1, w, strides = [1,1,1,1], padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu = tf.nn.relu(bias, name = scope)\n",
    "    # 局部响应归一化\n",
    "    lrn = tf.nn.lrn(relu, 4,bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='lrn2' )\n",
    "    # 池化\n",
    "    pool2 = tf.nn.max_pool(lrn, ksize = [1,3,3,1], strides = [1,2,2,1], padding = \"VALID\")\n",
    "\n",
    "    #卷积层三\n",
    "with tf.name_scope(\"conv3\") as scope:\n",
    "    # 实际 384 核,相同 \n",
    "    w = weights_initializer(shape = [3, 3, 256, 384], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [384],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(pool2, w, strides = [1,1,1,1], padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu3 = tf.nn.relu(bias, name = scope)\n",
    "\n",
    "    #卷积层四\n",
    "with tf.name_scope(\"conv4\") as scope:\n",
    "    # 实际 384 核\n",
    "    w = weights_initializer(shape = [3, 3, 384, 384], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [384],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(relu3, w, strides = [1,1,1,1], padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu4 = tf.nn.relu(bias, name = scope)\n",
    "\n",
    "    #卷积层五\n",
    "with tf.name_scope(\"conv5\") as scope:\n",
    "    # 实际 256核\n",
    "    w = weights_initializer(shape = [3, 3, 384, 256], stddev = 0.1)\n",
    "    b = bias_initializer(shape = [256],constant = 0.0)\n",
    "    # 卷积+偏置\n",
    "    conv = tf.nn.conv2d(relu4, w, strides = [1,1,1,1], padding = \"SAME\")\n",
    "    bias = tf.nn.bias_add(conv, b)\n",
    "    # RELU\n",
    "    relu = tf.nn.relu(bias, name = scope)\n",
    "    # 池化\n",
    "    pool5 = tf.nn.max_pool(relu, ksize = [1,3,3,1], strides = [1,2,2,1], padding = \"VALID\")\n",
    "    \n",
    "    #全连接层一\n",
    "with tf.name_scope(\"full_connect1\") as scope:\n",
    "    w, b = fc_weights_initializer(6*6*256, 4096, constant = 0.0)\n",
    "    # 展开图像到Vector\n",
    "    flattened = tf.reshape(pool5,shape = [-1, 6*6*256])\n",
    "    # 全连接一\n",
    "    fc1 = tf.add(tf.matmul(flattened, w), b)\n",
    "    # \n",
    "    dropout1 = tf.nn.dropout(fc1, keep_prob = 0.5)\n",
    "    \n",
    "    #全连接层二\n",
    "with tf.name_scope(\"full_connect2\") as scope:\n",
    "    w, b = fc_weights_initializer(4096, 4096, constant = 0.0)\n",
    "    # 全连接二\n",
    "    fc2 = tf.add(tf.matmul(dropout1, w), b)\n",
    "    # \n",
    "    dropout2 = tf.nn.dropout(fc2, keep_prob = 0.5)\n",
    "\n",
    "    #全连接层三\n",
    "with tf.name_scope(\"full_connect3\") as scope:\n",
    "    # 输出3类\n",
    "    w, b = fc_weights_initializer(4096, 3, constant = 0.0)\n",
    "    # 全连接三\n",
    "    fc3 = tf.add(tf.matmul(dropout2, w), b)\n",
    "    # softmax处理\n",
    "    y_ = tf.nn.softmax(fc3)\n",
    "\n",
    "#x = tf.placeholder(tf.float32,shape = [None, image_width,image_height,image_channels])\n",
    "#y = tf.placeholder(tf.float32,shape = [None, image_width,image_height,image_channels])\n",
    "# 定义训练代价函数\n",
    "#cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = fc3, labels = y))\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# 定义梯度优化算法\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "# 评估精确度\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value conv4/Variable\n\t [[Node: conv4/Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv4/Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv4/Variable)]]\n\t [[Node: _arg_input/Placeholder_1_0_1/_16 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_728__arg_input/Placeholder_1_0_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_1_0_1)]]\n\nCaused by op 'conv4/Variable/read', defined at:\n  File \"/home/lile/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lile/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-749db9be9fce>\", line 78, in <module>\n    w = weights_initializer(shape = [3, 3, 384, 384], stddev = 0.1)\n  File \"<ipython-input-8-749db9be9fce>\", line 15, in weights_initializer\n    weights = tf.Variable(tf.truncated_normal(shape,stddev = stddev))\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 200, in __init__\n    expected_shape=expected_shape)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 319, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1303, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2514, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv4/Variable\n\t [[Node: conv4/Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv4/Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv4/Variable)]]\n\t [[Node: _arg_input/Placeholder_1_0_1/_16 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_728__arg_input/Placeholder_1_0_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_1_0_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv4/Variable\n\t [[Node: conv4/Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv4/Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv4/Variable)]]\n\t [[Node: _arg_input/Placeholder_1_0_1/_16 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_728__arg_input/Placeholder_1_0_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_1_0_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-70259d8830ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#if i % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#train_accuracy = sess.run(accuracy,feed_dict = {x:})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlab_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"loss = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#sess.run(train_step,feed_dict = {x:image_batch, y:label_batch})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 999\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m   1000\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1134\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv4/Variable\n\t [[Node: conv4/Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv4/Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv4/Variable)]]\n\t [[Node: _arg_input/Placeholder_1_0_1/_16 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_728__arg_input/Placeholder_1_0_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_1_0_1)]]\n\nCaused by op 'conv4/Variable/read', defined at:\n  File \"/home/lile/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lile/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-749db9be9fce>\", line 78, in <module>\n    w = weights_initializer(shape = [3, 3, 384, 384], stddev = 0.1)\n  File \"<ipython-input-8-749db9be9fce>\", line 15, in weights_initializer\n    weights = tf.Variable(tf.truncated_normal(shape,stddev = stddev))\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 200, in __init__\n    expected_shape=expected_shape)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 319, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1303, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2514, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/lile/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv4/Variable\n\t [[Node: conv4/Variable/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv4/Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv4/Variable)]]\n\t [[Node: _arg_input/Placeholder_1_0_1/_16 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_728__arg_input/Placeholder_1_0_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_1_0_1)]]\n"
     ]
    }
   ],
   "source": [
    "num_iter = 3000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #在迭代控制中,记得添加tf.initialize_local_variables(),官网教程没有说明,但是如过不加，会出错\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess = sess, coord = coord)\n",
    "    \n",
    "    #y1,y2 = sess.run([image_batch, label_batch])\n",
    "    \n",
    "    #训练\n",
    "    for i in range(num_iter):\n",
    "        img_batch, lab_batch = sess.run([image_batch,label_batch])\n",
    "        #if i % 100 == 0:\n",
    "            #train_accuracy = sess.run(accuracy,feed_dict = {x:})\n",
    "        loss = sess.run(train_step,feed_dict = {x:img_batch, y:lab_batch})\n",
    "        print(\"step \" + str(i) + \"loss = \" + loss)\n",
    "        #sess.run(train_step,feed_dict = {x:image_batch, y:label_batch})\n",
    "        \n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y1.shape)\n",
    "plt.figure(0)\n",
    "plt.imshow(y1[0])\n",
    "plt.figure(1)\n",
    "plt.imshow(y1[1])\n",
    "plt.figure(2)\n",
    "plt.imshow(y1[2])\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

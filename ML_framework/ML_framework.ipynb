{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 、文件位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_path = \"./image/train\"\n",
    "testset_path = \"./image/test\"\n",
    "output_path = \"./output\"\n",
    "\n",
    "image_width = 24\n",
    "image_height = 24\n",
    "image_channels = 3\n",
    "\n",
    "#总共3类\n",
    "num_breed = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、创建 TFRecords文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import groupby\n",
    "from scipy import misc\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# class 信息\n",
    "breeds_with_path = glob.glob(trainset_path + \"/*\")\n",
    "breeds = list(map(lambda x:x.split(\"/\")[3],breeds_with_path))\n",
    "breeds_dict = dict(zip(breeds, [x for x in range(len(breeds))]))\n",
    "#print(breeds_with_path,breeds_dict,[x for x in range(len(breeds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_record(dataset_path,output_location):\n",
    "    # 获取数据集下所有文件路径\n",
    "    dataset_files = glob.glob(dataset_path + \"/*/*.jpg\")\n",
    "    # 分离出claess信息,得到（class,file_path）对的列表\n",
    "    image_filepath_with_breed = list(map(lambda file_path:(file_path.split(\"/\")[3],file_path),dataset_files))\n",
    "    \n",
    "    #每个TFRecord文件保存10个图片\n",
    "    nums_per_file = 10\n",
    "    writer = None\n",
    "    \n",
    "    # 记录当前读到的图像index\n",
    "    current_index = 0\n",
    "    for breed, file_path in image_filepath_with_breed:\n",
    "        if current_index % nums_per_file == 0:\n",
    "            if writer:\n",
    "                print(\"current_index = \",current_index,\"\\n\")\n",
    "                writer.close()\n",
    "            \n",
    "            # 格式化字符串\n",
    "            record_filename = \"{output_location}{current_index}.tfrecords\".format(\n",
    "            output_location = output_location,\n",
    "            current_index = current_index)\n",
    "            \n",
    "            writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "            \n",
    "        current_index += 1\n",
    "        \n",
    "        # 读取图像并转换为tf.example格式\n",
    "        image = misc.imread(file_path)\n",
    "            \n",
    "        # 图像转换为Byte型\n",
    "        image_raw = image.tobytes()\n",
    "        \n",
    "        example = tf.train.Example(features = \n",
    "                                  tf.train.Features(feature = {\n",
    "                    \"label\": tf.train.Feature(int64_list = tf.train.Int64List(value = [breeds_dict[breed]])),\n",
    "                    \"image_raw\": tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_raw]))   \n",
    "                }     \n",
    "            )    \n",
    "        )\n",
    "        \n",
    "        # 写入文件\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    # 关闭最后一个文件\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create_record(trainset_path,output_path + \"/training-images/\")\n",
    "#create_record(testset_path,output_path + \"/testing-images/\")\n",
    "print(\"finished\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、 读取TFRecord 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames =tf.train.match_filenames_once(output_path + \"/training-images/*.tfrecords\")\n",
    "#[\"/home/lile/ML_learning/ML_framework/output/training-images/10.tfrecords\",\"/home/lile/ML_learning/ML_framework/output/training-images/0.tfrecords\"] #\n",
    "filenames_queue = tf.train.string_input_producer(filenames, shuffle = True)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filenames_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features = {\n",
    "        \"label\":tf.FixedLenFeature([],tf.int64),\n",
    "        \"image_raw\":tf.FixedLenFeature([],tf.string)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解码图像数据\n",
    "im = tf.decode_raw(features[\"image_raw\"],tf.uint8) \n",
    "reshape = tf.reshape(im,(image_height,image_width,image_channels))\n",
    "image = tf.cast(reshape,tf.float32)\n",
    "label = tf.cast(features[\"label\"],tf.int64)\n",
    "\n",
    "\n",
    "# 组合训练数据\n",
    "batch_size = 5\n",
    "min_after_dequeue = 100*batch_size\n",
    "capacity = min_after_dequeue + 3*batch_size\n",
    "\n",
    "image_batch, label_batch = tf.train.shuffle_batch(\n",
    "(image,label),batch_size = batch_size,\n",
    "capacity = capacity,min_after_dequeue = min_after_dequeue\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### 各层图片尺寸 \n",
    "# input   [batch_size, 224, 224, 3]\n",
    "# conv1   [32, 56, 56, 64]\n",
    "# pool1   [32, 27, 27, 64]\n",
    "# conv2   [32, 27, 27, 192]\n",
    "# pool2   [32, 13, 13, 192]\n",
    "# conv3   [32, 13, 13, 384]\n",
    "# conv4   [32, 13, 13, 256]\n",
    "# conv5   [32, 13, 13, 256]\n",
    "# pool5   [32, 6, 6, 256]\n",
    "\n",
    "\n",
    "# 定义w,b初始化函数\n",
    "def variable_with_weight_loss(shape, stddev, wl):\n",
    "    var = tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "    if wl is not None:\n",
    "        weight_loss = tf.multiply(tf.nn.l2_loss(var), wl, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_loss)\n",
    "    return var\n",
    "\n",
    "\n",
    "#def interface(x):\n",
    "    # 输入层\n",
    "with tf.name_scope(\"input\") as scope:\n",
    "    x = tf.placeholder(tf.float32,shape = [None, image_height, image_width, image_channels], name = \"x_input\")\n",
    "    y = tf.placeholder(tf.int64,shape = [batch_size],name = \"y_input\")\n",
    "    #x = image_batch\n",
    "    #y = label_batch\n",
    "    tf.summary.image(\"image_input\",x, batch_size)\n",
    "\n",
    "    #卷积层一\n",
    "with tf.name_scope(\"conv1\") as scope:\n",
    "    weight1 = variable_with_weight_loss(shape=[5, 5, 3, 64], stddev=5e-2, wl=0.0)\n",
    "    kernel1 = tf.nn.conv2d(x, weight1, [1, 1, 1, 1], padding='SAME')\n",
    "    bias1 = tf.Variable(tf.constant(0.0, shape=[64]))\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(kernel1, bias1))\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    \n",
    "    tf.summary.histogram(\"weight1\",weight1)\n",
    "    \n",
    "    #卷积层二\n",
    "with tf.name_scope(\"conv2\") as scope:\n",
    "    weight2 = variable_with_weight_loss(shape=[5, 5, 64, 64], stddev=5e-2, wl=0.0)\n",
    "    kernel2 = tf.nn.conv2d(norm1, weight2, [1, 1, 1, 1], padding='SAME')\n",
    "    bias2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(kernel2, bias2))\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    tf.summary.histogram(\"weight2\",weight2)\n",
    "\n",
    "    #全连接层一\n",
    "with tf.name_scope(\"full_connect1\") as scope:\n",
    "    reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "    weight3 = variable_with_weight_loss(shape=[6*6*64, 384], stddev=0.04, wl=0.004)\n",
    "    bias3 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weight3) + bias3)\n",
    "    \n",
    "    tf.summary.histogram(\"weight3\",weight3)\n",
    "    \n",
    "    #全连接层二\n",
    "with tf.name_scope(\"full_connect2\") as scope:\n",
    "    weight4 = variable_with_weight_loss(shape=[384, 192], stddev=0.04, wl=0.004)\n",
    "    bias4 = tf.Variable(tf.constant(0.1, shape=[192]))                                      \n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weight4) + bias4)\n",
    "    \n",
    "    tf.summary.histogram(\"weight4\",weight4)\n",
    "    \n",
    "    #全连接层三\n",
    "with tf.name_scope(\"full_connect3\") as scope:\n",
    "    weight5 = variable_with_weight_loss(shape=[192, 3], stddev=1/192.0, wl=0.0)\n",
    "    bias5 = tf.Variable(tf.constant(0.0, shape=[3]))\n",
    "    logits = tf.add(tf.matmul(local4, weight5), bias5)\n",
    "    \n",
    "    tf.summary.histogram(\"weight5\",weight5)\n",
    "    # softmax处理\n",
    "    #y_ = tf.nn.softmax(fc3)\n",
    "    \n",
    "with tf.name_scope(\"cross_entropy\") as scope:\n",
    "    # 定义训练代价函数\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = y))\n",
    "\n",
    "    tf.summary.scalar(\"cross_entropy\",cross_entropy)\n",
    "    \n",
    "#cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "# 定义梯度优化算法\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 评估精确度\n",
    "#correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(y,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 汇总数据\n",
    "log_dir = \"./logdir\"\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "#test_writer = tf.summary.FileWriter(log_dir + '/test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training......\n",
      "\n",
      "0 0.800055\n",
      "10 1.13784\n",
      "20 1.46381\n",
      "30 1.04644\n",
      "40 0.677248\n",
      "50 1.20038\n",
      "60 0.699789\n",
      "70 1.21471\n",
      "80 1.02347\n",
      "90 1.17041\n",
      "100 0.938611\n",
      "110 0.712419\n",
      "120 0.900339\n",
      "130 0.96708\n",
      "140 0.535829\n",
      "150 1.03887\n",
      "160 0.841516\n",
      "170 1.64269\n",
      "180 0.932998\n",
      "190 1.14178\n",
      "200 0.789508\n",
      "210 1.15049\n",
      "220 0.857313\n",
      "230 1.13796\n",
      "240 0.515376\n",
      "250 0.7717\n",
      "260 0.356558\n",
      "270 0.86998\n",
      "280 0.485585\n",
      "290 0.731056\n",
      "300 0.699039\n",
      "310 0.532303\n",
      "320 0.631616\n",
      "330 0.266884\n",
      "340 0.549602\n",
      "350 0.650543\n",
      "360 0.682331\n",
      "370 0.606728\n",
      "380 0.545595\n",
      "390 0.443321\n",
      "400 0.738283\n",
      "410 0.379079\n",
      "420 0.613683\n",
      "430 0.45776\n",
      "440 0.391887\n",
      "450 0.305967\n",
      "460 0.130578\n",
      "470 0.512787\n",
      "480 0.649019\n",
      "490 0.467492\n",
      "500 0.132391\n",
      "510 0.914404\n",
      "520 0.468524\n",
      "530 0.482923\n",
      "540 0.339596\n",
      "550 0.365091\n",
      "560 0.117273\n",
      "570 0.438364\n",
      "580 0.512281\n",
      "590 0.18732\n",
      "600 0.399005\n",
      "610 0.181386\n",
      "620 0.123407\n",
      "630 0.143097\n",
      "640 0.074688\n",
      "650 0.12731\n",
      "660 0.149209\n",
      "670 0.069649\n",
      "680 0.229643\n",
      "690 0.0977665\n",
      "700 0.103226\n",
      "710 0.304361\n",
      "720 0.21018\n",
      "730 0.102874\n",
      "740 0.0859557\n",
      "750 0.124427\n",
      "760 0.0983168\n",
      "770 0.00941902\n",
      "780 0.0193613\n",
      "790 0.035314\n",
      "800 0.0591446\n",
      "810 0.143329\n",
      "820 0.072536\n",
      "830 0.0491219\n",
      "840 0.0183152\n",
      "850 0.0686904\n",
      "860 0.0167003\n",
      "870 0.0226701\n",
      "880 0.032245\n",
      "890 0.0139999\n",
      "900 0.00675844\n",
      "910 0.0091656\n",
      "920 0.0817897\n",
      "930 0.0223841\n",
      "940 0.00225801\n",
      "950 0.0519247\n",
      "960 0.00617255\n",
      "970 0.00698262\n",
      "980 0.0107561\n",
      "990 0.0226528\n",
      "1000 0.0142951\n",
      "1010 0.00221137\n",
      "1020 0.0355064\n",
      "1030 0.00227654\n",
      "1040 0.00380758\n",
      "1050 0.00758872\n",
      "1060 0.00142465\n",
      "1070 0.00170579\n",
      "1080 0.00836526\n",
      "1090 0.0164715\n",
      "1100 0.00934562\n",
      "1110 0.00627544\n",
      "1120 0.00594933\n",
      "1130 0.00211385\n",
      "1140 0.00247138\n",
      "1150 0.00425811\n",
      "1160 0.00167959\n",
      "1170 0.00282812\n",
      "1180 0.00547472\n",
      "1190 0.00552688\n",
      "1200 0.00457235\n",
      "1210 0.00106163\n",
      "1220 0.0095069\n",
      "1230 0.00619643\n",
      "1240 0.00125896\n",
      "1250 0.000792935\n",
      "1260 0.00282985\n",
      "1270 0.00333232\n",
      "1280 0.00210583\n",
      "1290 0.00102211\n",
      "1300 0.00264401\n",
      "1310 0.00376038\n",
      "1320 0.000887338\n",
      "1330 0.000726728\n",
      "1340 0.000755681\n",
      "1350 0.00196588\n",
      "1360 0.00721289\n",
      "1370 0.00253213\n",
      "1380 0.00159774\n",
      "1390 0.00185538\n",
      "1400 0.000148871\n",
      "1410 0.000765539\n",
      "1420 0.00171872\n",
      "1430 0.00628979\n",
      "1440 0.00239391\n",
      "1450 0.00300871\n",
      "1460 0.000516694\n",
      "1470 0.00397937\n",
      "1480 0.000359478\n",
      "1490 0.00115686\n",
      "1500 0.000515099\n",
      "1510 0.00169232\n",
      "1520 0.00267358\n",
      "1530 0.000720628\n",
      "1540 0.00189691\n",
      "1550 0.00276884\n",
      "1560 0.0017831\n",
      "1570 0.000615766\n",
      "1580 0.00319388\n",
      "1590 0.00277335\n",
      "1600 0.00308185\n",
      "1610 0.00187981\n",
      "1620 0.00060566\n",
      "1630 0.00264125\n",
      "1640 0.000488168\n",
      "1650 0.000947998\n",
      "1660 0.000239816\n",
      "1670 0.00123888\n",
      "1680 0.00366138\n",
      "1690 0.000559239\n",
      "1700 0.000978742\n",
      "1710 0.000655368\n",
      "1720 0.000465849\n",
      "1730 0.0011315\n",
      "1740 0.000645779\n",
      "1750 0.00103236\n",
      "1760 0.00154703\n",
      "1770 0.00163553\n",
      "1780 0.00130571\n",
      "1790 0.00140174\n",
      "1800 0.00150986\n",
      "1810 0.000603879\n",
      "1820 0.000470933\n",
      "1830 0.000781329\n",
      "1840 0.000280552\n",
      "1850 0.00053886\n",
      "1860 0.000204892\n",
      "1870 0.0012674\n",
      "1880 0.000405083\n",
      "1890 0.00233068\n",
      "1900 0.00207519\n",
      "1910 0.000142225\n",
      "1920 0.000379603\n",
      "1930 0.00169595\n",
      "1940 0.00124508\n",
      "1950 0.00116495\n",
      "1960 0.00120438\n",
      "1970 0.000340261\n",
      "1980 4.51073e-05\n",
      "1990 0.00131027\n",
      "2000 0.000733292\n",
      "2010 0.00165054\n",
      "2020 0.000871407\n",
      "2030 0.000376787\n",
      "2040 0.00121418\n",
      "2050 0.00030811\n",
      "2060 0.000462728\n",
      "2070 0.000811566\n",
      "2080 0.000897732\n",
      "2090 0.000491304\n",
      "2100 0.000566015\n",
      "2110 0.00154598\n",
      "2120 0.000210656\n",
      "2130 0.000433382\n",
      "2140 0.000257795\n",
      "2150 0.000741165\n",
      "2160 0.000472009\n",
      "2170 0.000258818\n",
      "2180 0.00117971\n",
      "2190 0.000353755\n",
      "2200 0.000213107\n",
      "2210 0.000488892\n",
      "2220 0.00111461\n",
      "2230 0.000104273\n",
      "2240 0.00111284\n",
      "2250 0.00018189\n",
      "2260 0.000477044\n",
      "2270 0.000127585\n",
      "2280 0.0001815\n",
      "2290 0.000282145\n",
      "2300 0.000265489\n",
      "2310 0.000222268\n",
      "2320 0.000358006\n",
      "2330 0.000268359\n",
      "2340 0.000257421\n",
      "2350 9.17349e-05\n",
      "2360 0.000206198\n",
      "2370 0.000430526\n",
      "2380 0.000521935\n",
      "2390 0.000119532\n",
      "2400 0.000294777\n",
      "2410 0.000132876\n",
      "2420 0.000283725\n",
      "2430 0.000359237\n",
      "2440 0.000370259\n",
      "2450 0.000483801\n",
      "2460 0.000285385\n",
      "2470 0.000111983\n",
      "2480 0.000399992\n",
      "2490 0.000119006\n",
      "2500 0.000110684\n",
      "2510 0.000243201\n",
      "2520 0.000241328\n",
      "2530 0.000297095\n",
      "2540 0.000172898\n",
      "2550 0.000727661\n",
      "2560 0.000109002\n",
      "2570 0.000586168\n",
      "2580 0.000157735\n",
      "2590 0.00013848\n",
      "2600 0.000323688\n",
      "2610 0.000157661\n",
      "2620 0.000259729\n",
      "2630 0.000215535\n",
      "2640 4.46528e-05\n",
      "2650 0.000218653\n",
      "2660 0.000472186\n",
      "2670 9.61716e-05\n",
      "2680 0.000145993\n",
      "2690 0.000121036\n",
      "2700 0.000109944\n",
      "2710 0.000377525\n",
      "2720 8.53454e-05\n",
      "2730 0.00014973\n",
      "2740 7.69573e-05\n",
      "2750 6.35593e-05\n",
      "2760 6.47017e-05\n",
      "2770 0.000629426\n",
      "2780 0.000169949\n",
      "2790 0.000177208\n",
      "2800 0.000212827\n",
      "2810 9.23546e-05\n",
      "2820 0.000164028\n",
      "2830 0.000228779\n",
      "2840 3.08266e-05\n",
      "2850 5.09952e-05\n",
      "2860 0.00012406\n",
      "2870 3.56185e-05\n",
      "2880 4.8277e-05\n",
      "2890 0.000143741\n",
      "2900 9.99501e-05\n",
      "2910 0.000124395\n",
      "2920 0.000187593\n",
      "2930 0.000149796\n",
      "2940 4.74184e-05\n",
      "2950 0.000320197\n",
      "2960 0.000373935\n",
      "2970 0.000229888\n",
      "2980 0.000444956\n",
      "2990 3.10414e-05\n",
      "stop training.\n",
      "\n",
      "finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_iter = 3000\n",
    "init = [tf.global_variables_initializer(),tf.local_variables_initializer()]\n",
    "with tf.Session() as sess:\n",
    "    #在迭代控制中,记得添加tf.initialize_local_variables(),官网教程没有说明,但是如过不加，会出错\n",
    "    sess.run(init)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess = sess, coord = coord)\n",
    "    \n",
    "    #y1,y2 = sess.run([image_batch, label_batch])\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "    #训练    \n",
    "    print(\"start training......\\n\")\n",
    "    for step in range(num_iter):\n",
    "        \n",
    "       \n",
    "        images_batch,labels_batch = sess.run([image_batch,label_batch])\n",
    "        #print(images_batch.shape,labels_batch.shape,images_batch.dtype,labels_batch.dtype)\n",
    "        \n",
    "        _ = sess.run(train_step, feed_dict = {x:images_batch,y:labels_batch})\n",
    "        \n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            summary, loss_value  = sess.run([merged, cross_entropy],feed_dict = {x:images_batch,y:labels_batch})\n",
    "            #format_str = ('step %d, loss = %.2f')\n",
    "            print(step,loss_value)\n",
    "            train_writer.add_summary(summary, step)\n",
    "    \n",
    "     \n",
    "    train_writer.close()\n",
    "    print(\"stop training.\\n\")\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    print(\"finished.\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
